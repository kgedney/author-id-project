{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exp1_text_preprocessing_and_modeling.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kgedney/author-id-project/blob/master/exp1_text_preprocessing_and_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Lu4PRj6EOqVP"
      },
      "cell_type": "markdown",
      "source": [
        "### Preprocess Text Data and Modelling with Name-Entities Intacted\n",
        "### ANLY 590 Project\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "n8Z-jpowOqVR"
      },
      "cell_type": "markdown",
      "source": [
        "***"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SSt2URxSOqVa"
      },
      "cell_type": "markdown",
      "source": [
        "#### Google Colab Prep"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Rm4u23MHa1AE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "W4WEkqUsOqVb",
        "outputId": "372ad6f7-e01b-4ee9-f034-704cf4f59ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# get data from Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bvcwoRHOtB6J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Loading subsetted dataset with 9,999 rows and 14 authors"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QJ11dU2QOqVe",
        "outputId": "fc8051b3-d0cd-407b-9894-f2bf5464028c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "# manually add file from local to drive\n",
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/filtered_data_sub.csv')\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>body</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>permalink</th>\n",
              "      <th>num_chars</th>\n",
              "      <th>num_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GuaranteedAdmission</td>\n",
              "      <td>You can be in favor of a policy he supports an...</td>\n",
              "      <td>AskReddit</td>\n",
              "      <td>/r/AskReddit/comments/9zklcs/as_a_brit_who_onl...</td>\n",
              "      <td>74</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GuaranteedAdmission</td>\n",
              "      <td>That depends. What is the penalty for breaking...</td>\n",
              "      <td>AskReddit</td>\n",
              "      <td>/r/AskReddit/comments/9zkfcd/how_would_you_fee...</td>\n",
              "      <td>202</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GuaranteedAdmission</td>\n",
              "      <td>Because I like to think long term. Tax cuts fo...</td>\n",
              "      <td>AskReddit</td>\n",
              "      <td>/r/AskReddit/comments/9yxl98/liberals_of_reddi...</td>\n",
              "      <td>120</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GuaranteedAdmission</td>\n",
              "      <td>We don't talk about the Highway Shoes, OP! Are...</td>\n",
              "      <td>AskReddit</td>\n",
              "      <td>/r/AskReddit/comments/9yrbvd/people_who_lost_a...</td>\n",
              "      <td>110</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GuaranteedAdmission</td>\n",
              "      <td>Are you badmouthing Mistress Luna, infidel? A ...</td>\n",
              "      <td>Stellaris</td>\n",
              "      <td>/r/Stellaris/comments/9y9y1j/oh_ok_then/ea12kh0/</td>\n",
              "      <td>93</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                author                                               body  \\\n",
              "0  GuaranteedAdmission  You can be in favor of a policy he supports an...   \n",
              "1  GuaranteedAdmission  That depends. What is the penalty for breaking...   \n",
              "2  GuaranteedAdmission  Because I like to think long term. Tax cuts fo...   \n",
              "3  GuaranteedAdmission  We don't talk about the Highway Shoes, OP! Are...   \n",
              "4  GuaranteedAdmission  Are you badmouthing Mistress Luna, infidel? A ...   \n",
              "\n",
              "   subreddit                                          permalink  num_chars  \\\n",
              "0  AskReddit  /r/AskReddit/comments/9zklcs/as_a_brit_who_onl...         74   \n",
              "1  AskReddit  /r/AskReddit/comments/9zkfcd/how_would_you_fee...        202   \n",
              "2  AskReddit  /r/AskReddit/comments/9yxl98/liberals_of_reddi...        120   \n",
              "3  AskReddit  /r/AskReddit/comments/9yrbvd/people_who_lost_a...        110   \n",
              "4  Stellaris   /r/Stellaris/comments/9y9y1j/oh_ok_then/ea12kh0/         93   \n",
              "\n",
              "   num_words  \n",
              "0         17  \n",
              "1         36  \n",
              "2         22  \n",
              "3         22  \n",
              "4         15  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "LyH_kjBnjo_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92146cc5-9d5e-4e0a-d0a6-9a167119c677"
      },
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "O_Nh1qcIYl6S",
        "outputId": "3ce716e2-06ee-4d2a-82e5-3bef72a344a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "cell_type": "code",
      "source": [
        "# download nltk\n",
        "import nltk\n",
        "nltk.download('popular')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bJeXBWrvOqVg"
      },
      "cell_type": "markdown",
      "source": [
        "#### Text Cleaning\n",
        "\n",
        "ref: https://www.analyticsvidhya.com/blog/2018/02/the-different-methods-deal-text-data-predictive-python/"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EHcxp11nOqVg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remove URLs and replace as '<url>'\n",
        "import re\n",
        "df['body_no_urls'] = df.apply(lambda row: re.sub(r\"http\\S+\", \"<url>\", row['body']), axis=1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9-JkOW2-OqVl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "df['tokenized_nltk']  = df.apply(lambda row: word_tokenize(row['body_no_urls']), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jouchqjcOqVw"
      },
      "cell_type": "markdown",
      "source": [
        "***"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "muQGleHGOqVx"
      },
      "cell_type": "markdown",
      "source": [
        "#### Preprocess  for Modelling"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZxVtQyhwOqVy",
        "outputId": "691c38af-8bad-41dc-cd91-360c1d1b2ab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# install packages\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "import keras\n",
        "from keras import optimizers\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, CuDNNLSTM, LSTM, Embedding, Bidirectional, GlobalAveragePooling1D, Conv1D, Activation, Flatten, Dropout, MaxPooling1D, Embedding, GlobalMaxPooling1D\n",
        "\n",
        "from keras.layers.core import Dense, Dropout"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2ToC3POKOqVz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create class assignments\n",
        "df['author_id'] = pd.Categorical(df.author).codes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pQZCE5H7OqV1"
      },
      "cell_type": "markdown",
      "source": [
        "#### 0. Baseline Model: Linear SVM"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "U8LagNfdOqV2",
        "outputId": "063b4484-c091-4923-8baa-ef8bd82a9bee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x = df['body'].values\n",
        "y = df['author_id'].values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=22)\n",
        "\n",
        "tfidf_vec   = TfidfVectorizer()\n",
        "x_train_vec = tfidf_vec.fit_transform(x_train)\n",
        "x_test_vec  = tfidf_vec.transform(x_test)\n",
        "x_train_vec.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7999, 20458)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FLAMT9ioOqV6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "clf             = LinearSVC().fit(x_train_vec, y_train)\n",
        "predicted       = clf.predict(x_test_vec)\n",
        "predicted_score = clf.decision_function(x_test_vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0x4wr9ziOqV9",
        "outputId": "e7de13be-4004-48ad-8086-1f6ab98741b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('accuracy', metrics.accuracy_score(y_test, predicted))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.5805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ycStNkaYNWwd",
        "outputId": "a08e840c-0f4b-4b70-a00b-46c9b2b94c92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# top k accuracy (# ref: https://scikit-learn.org/stable/modules/svm.html)\n",
        "predicted_score = clf.decision_function(x_test_vec)\n",
        "predicted_score.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-2aH0jUsNZeP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# transform matrix of predictions to put them in order\n",
        "best_n = predicted_score.argsort()[:,::-1] # need to do in reverse order thats why need \"[::-1]\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OX4iMj0LNbBP",
        "outputId": "68f448c0-ab34-4c5b-cb1a-67ca4e6928f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# set up function to calculate\n",
        "count = 0\n",
        "for i in range(0, y_test.shape[0]):\n",
        "    if (y_test[i] in best_n[i,0:5]):\n",
        "        count = count + 1\n",
        "\n",
        "top_5_acc = count / y_test.shape[0]\n",
        "top_5_acc"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8695"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TMyJAaDMOqWA"
      },
      "cell_type": "markdown",
      "source": [
        "#### Preprocess Data for Keras Models"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qZT9aqDkOqWA",
        "outputId": "50a77d83-cc3f-4ee5-844a-ccb3a269f784",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# data preprocess\n",
        "x = df['tokenized_nltk'].values\n",
        "y = df['author_id'].values\n",
        "\n",
        "# create sequences\n",
        "max_features = 25000\n",
        "tokenizer    = Tokenizer(num_words = max_features)\n",
        "tokenizer.fit_on_texts(x)\n",
        "x_sequences  = tokenizer.texts_to_sequences(x)\n",
        "\n",
        "# pad each sequence to be max length\n",
        "maxlen = max(len(x) for x in x_sequences)\n",
        "print(maxlen)\n",
        "x_sequences = sequence.pad_sequences(x_sequences, maxlen)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QpCgS_kgmAin",
        "outputId": "673af8c3-8594-4811-8af7-823e94a18256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# from keras.utils import to_categorical\n",
        "# print(y.shape)\n",
        "# y = to_categorical(y)\n",
        "# print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(72662,)\n",
            "(72662, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0DGqh3gtOqWC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# split test and train\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_sequences, y, test_size=0.20, random_state=22)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ACtPY2hyOqWS"
      },
      "cell_type": "markdown",
      "source": [
        "#### 1. Faster RNN Model: CuDNNLSTM "
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "7Uxo-JLmYl7I"
      },
      "cell_type": "markdown",
      "source": [
        "- Run on Google Colab, 14 mins.    \n",
        "- Very overfit"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wjN0EYtzOqWT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ref: https://keras.io/layers/recurrent/#cudnnlstm\n",
        "# faster LSTM implementation\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Embedding(input_dim=max_features,\n",
        "                     output_dim=128))\n",
        "model1.add(CuDNNLSTM(128))\n",
        "model1.add(Dropout(0.5))\n",
        "model1.add(Dense(14, activation=\"softmax\"))\n",
        "\n",
        "model1.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qS9g-XvpOqWY",
        "outputId": "5e5c0c2a-5f3e-4e73-cc4b-039f59de8dcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "cell_type": "code",
      "source": [
        "history1 = model1.fit(x_train, y_train,\n",
        "            batch_size=128,\n",
        "            epochs=16,\n",
        "            validation_data=(x_test, y_test))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7999 samples, validate on 2000 samples\n",
            "Epoch 1/16\n",
            "7999/7999 [==============================] - 6s 756us/step - loss: 2.5363 - acc: 0.1413 - val_loss: 2.3142 - val_acc: 0.2250\n",
            "Epoch 2/16\n",
            "7999/7999 [==============================] - 4s 483us/step - loss: 2.1086 - acc: 0.2755 - val_loss: 2.0968 - val_acc: 0.2560\n",
            "Epoch 3/16\n",
            "7999/7999 [==============================] - 4s 478us/step - loss: 1.7700 - acc: 0.3749 - val_loss: 1.9232 - val_acc: 0.3335\n",
            "Epoch 4/16\n",
            "7999/7999 [==============================] - 4s 482us/step - loss: 1.3971 - acc: 0.5062 - val_loss: 1.7820 - val_acc: 0.4080\n",
            "Epoch 5/16\n",
            "7999/7999 [==============================] - 4s 481us/step - loss: 1.0176 - acc: 0.6698 - val_loss: 1.7945 - val_acc: 0.4375\n",
            "Epoch 6/16\n",
            "7999/7999 [==============================] - 4s 476us/step - loss: 0.6824 - acc: 0.7928 - val_loss: 1.8654 - val_acc: 0.4405\n",
            "Epoch 7/16\n",
            "7999/7999 [==============================] - 4s 475us/step - loss: 0.4225 - acc: 0.8751 - val_loss: 1.8894 - val_acc: 0.4770\n",
            "Epoch 8/16\n",
            "7999/7999 [==============================] - 4s 472us/step - loss: 0.2928 - acc: 0.9217 - val_loss: 2.0162 - val_acc: 0.4505\n",
            "Epoch 9/16\n",
            "7999/7999 [==============================] - 4s 481us/step - loss: 0.1966 - acc: 0.9494 - val_loss: 2.1565 - val_acc: 0.4870\n",
            "Epoch 10/16\n",
            "7999/7999 [==============================] - 4s 481us/step - loss: 0.1188 - acc: 0.9715 - val_loss: 2.1952 - val_acc: 0.4870\n",
            "Epoch 11/16\n",
            "7999/7999 [==============================] - 4s 475us/step - loss: 0.1687 - acc: 0.9560 - val_loss: 2.0424 - val_acc: 0.4530\n",
            "Epoch 12/16\n",
            "7999/7999 [==============================] - 4s 481us/step - loss: 0.1540 - acc: 0.9591 - val_loss: 2.3998 - val_acc: 0.4480\n",
            "Epoch 13/16\n",
            "7999/7999 [==============================] - 4s 482us/step - loss: 0.0842 - acc: 0.9819 - val_loss: 2.3650 - val_acc: 0.4905\n",
            "Epoch 14/16\n",
            "7999/7999 [==============================] - 4s 478us/step - loss: 0.0456 - acc: 0.9905 - val_loss: 2.4325 - val_acc: 0.5005\n",
            "Epoch 15/16\n",
            "7999/7999 [==============================] - 4s 483us/step - loss: 0.0365 - acc: 0.9922 - val_loss: 2.6389 - val_acc: 0.4900\n",
            "Epoch 16/16\n",
            "7999/7999 [==============================] - 4s 483us/step - loss: 0.0593 - acc: 0.9860 - val_loss: 2.6379 - val_acc: 0.4630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WtytRsl0OqWb",
        "outputId": "ba956174-c38d-4744-8aa4-abd0ada028ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('accuracy', model1.evaluate(x_test, y_test)[1])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 1s 602us/step\n",
            "accuracy 0.463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KKSaYcGAOqWe",
        "outputId": "24218070-adb8-4854-c83c-a2859e789e6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('accuracy', model1.evaluate(x_train, y_train)[1])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7999/7999 [==============================] - 4s 538us/step\n",
            "accuracy 0.9841230153769222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rJoHK6wBFppn",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "KOjFcZZWFrWs"
      },
      "cell_type": "markdown",
      "source": [
        "#### 2. CNN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SZ0QGhAPGXHg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_conv2 = Sequential()\n",
        "model_conv2.add(Embedding(max_features, output_dim = 30, input_length=229))\n",
        "model_conv2.add(Dropout(0.2))\n",
        "model_conv2.add(Conv1D(128, 5, activation='relu'))\n",
        "model_conv2.add(Conv1D(128, 5, activation='relu'))\n",
        "model_conv2.add(GlobalMaxPooling1D())\n",
        "model_conv2.add(Dropout(0.2))\n",
        "model_conv2.add(Dense(14, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NY6n9ha5GXKH",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "opt = optimizers.rmsprop(lr=0.001) # speed up optimization\n",
        "model_conv2.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hALcnyruGXMp",
        "outputId": "ca23f1b7-680d-4d0f-9248-e2746cd67398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "cell_type": "code",
      "source": [
        "history2 = model_conv2.fit(x_train, y_train,\n",
        "            batch_size=128,\n",
        "            epochs=16,\n",
        "            validation_data=(x_test, y_test))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7999 samples, validate on 2000 samples\n",
            "Epoch 1/16\n",
            "7999/7999 [==============================] - 2s 282us/step - loss: 2.5543 - acc: 0.1414 - val_loss: 2.3444 - val_acc: 0.2350\n",
            "Epoch 2/16\n",
            "7999/7999 [==============================] - 1s 178us/step - loss: 2.2095 - acc: 0.2540 - val_loss: 2.1579 - val_acc: 0.2760\n",
            "Epoch 3/16\n",
            "7999/7999 [==============================] - 1s 179us/step - loss: 2.0635 - acc: 0.2994 - val_loss: 2.0493 - val_acc: 0.3085\n",
            "Epoch 4/16\n",
            "7999/7999 [==============================] - 1s 176us/step - loss: 1.9012 - acc: 0.3592 - val_loss: 1.9464 - val_acc: 0.3510\n",
            "Epoch 5/16\n",
            "7999/7999 [==============================] - 1s 179us/step - loss: 1.7331 - acc: 0.4113 - val_loss: 1.8758 - val_acc: 0.3765\n",
            "Epoch 6/16\n",
            "7999/7999 [==============================] - 1s 180us/step - loss: 1.5532 - acc: 0.4797 - val_loss: 1.8307 - val_acc: 0.3895\n",
            "Epoch 7/16\n",
            "7999/7999 [==============================] - 1s 179us/step - loss: 1.3821 - acc: 0.5393 - val_loss: 1.8169 - val_acc: 0.4100\n",
            "Epoch 8/16\n",
            "7999/7999 [==============================] - 1s 178us/step - loss: 1.2279 - acc: 0.5957 - val_loss: 1.7864 - val_acc: 0.4270\n",
            "Epoch 9/16\n",
            "7999/7999 [==============================] - 1s 177us/step - loss: 1.0741 - acc: 0.6502 - val_loss: 1.8398 - val_acc: 0.4265\n",
            "Epoch 10/16\n",
            "7999/7999 [==============================] - 1s 178us/step - loss: 0.9474 - acc: 0.6976 - val_loss: 1.8286 - val_acc: 0.4385\n",
            "Epoch 11/16\n",
            "7999/7999 [==============================] - 1s 179us/step - loss: 0.8308 - acc: 0.7345 - val_loss: 1.8447 - val_acc: 0.4575\n",
            "Epoch 12/16\n",
            "7999/7999 [==============================] - 1s 179us/step - loss: 0.7232 - acc: 0.7721 - val_loss: 1.9699 - val_acc: 0.4620\n",
            "Epoch 13/16\n",
            "7999/7999 [==============================] - 1s 178us/step - loss: 0.6295 - acc: 0.8030 - val_loss: 1.9207 - val_acc: 0.4700\n",
            "Epoch 14/16\n",
            "7999/7999 [==============================] - 1s 177us/step - loss: 0.5372 - acc: 0.8324 - val_loss: 1.9978 - val_acc: 0.4665\n",
            "Epoch 15/16\n",
            "7999/7999 [==============================] - 1s 179us/step - loss: 0.4665 - acc: 0.8562 - val_loss: 2.0727 - val_acc: 0.4745\n",
            "Epoch 16/16\n",
            "7999/7999 [==============================] - 1s 183us/step - loss: 0.3960 - acc: 0.8800 - val_loss: 2.0847 - val_acc: 0.4800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "islqOUDZGXPS",
        "outputId": "81703f13-3c28-4dbc-8f17-0da15975f422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "model_conv2.evaluate(x_test,y_test)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 0s 190us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.084706964492798, 0.48]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "L6DoHbuMfvTS",
        "colab_type": "code",
        "outputId": "4d79f925-b6d8-49ce-b2b1-44f16ef80fc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "model_conv2.evaluate(x_train,y_train)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7999/7999 [==============================] - 1s 112us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1864259823502891, 0.9563695462007257]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "HxqC0VsOGBbF"
      },
      "cell_type": "markdown",
      "source": [
        "#### 3. CNN + LSTM"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KHV_jJyiGEmD",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_conv3 = Sequential()\n",
        "model_conv3.add(Embedding(max_features, output_dim = 30, input_length=229))\n",
        "model_conv3.add(Dropout(0.2))\n",
        "model_conv3.add(Conv1D(128, 5, activation='relu'))\n",
        "model_conv3.add(MaxPooling1D(4))\n",
        "model_conv3.add(LSTM(100))\n",
        "#model_conv.add(GlobalMaxPooling1D())\n",
        "\n",
        "model_conv3.add(Dense(14, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HKP5F_8cGEok",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt = optimizers.rmsprop(lr=0.001) # speed up optimization\n",
        "model_conv3.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "L-vX6kJWGErL",
        "outputId": "19e56ada-32f9-443e-ffe6-26b5e806777a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "cell_type": "code",
      "source": [
        "history3 = model_conv3.fit(x_train, y_train,\n",
        "            batch_size=128,\n",
        "            epochs=16,\n",
        "            validation_data=(x_test, y_test))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7999 samples, validate on 2000 samples\n",
            "Epoch 1/16\n",
            "7999/7999 [==============================] - 12s 2ms/step - loss: 2.5628 - acc: 0.1173 - val_loss: 2.4301 - val_acc: 0.1820\n",
            "Epoch 2/16\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 2.2036 - acc: 0.2572 - val_loss: 2.1784 - val_acc: 0.2605\n",
            "Epoch 3/16\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 1.9709 - acc: 0.3223 - val_loss: 2.0468 - val_acc: 0.2830\n",
            "Epoch 4/16\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 1.7752 - acc: 0.3884 - val_loss: 1.9633 - val_acc: 0.3190\n",
            "Epoch 5/16\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 1.5609 - acc: 0.4561 - val_loss: 1.9034 - val_acc: 0.3440\n",
            "Epoch 6/16\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 1.4046 - acc: 0.5056 - val_loss: 1.8812 - val_acc: 0.3660\n",
            "Epoch 7/16\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 1.2562 - acc: 0.5606 - val_loss: 1.9466 - val_acc: 0.3585\n",
            "Epoch 8/16\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 1.1153 - acc: 0.6058 - val_loss: 1.9805 - val_acc: 0.3690\n",
            "Epoch 9/16\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.9912 - acc: 0.6603 - val_loss: 1.9829 - val_acc: 0.3840\n",
            "Epoch 10/16\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.8758 - acc: 0.7063 - val_loss: 2.1812 - val_acc: 0.3730\n",
            "Epoch 11/16\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.7725 - acc: 0.7460 - val_loss: 2.0747 - val_acc: 0.4120\n",
            "Epoch 12/16\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.6654 - acc: 0.7833 - val_loss: 2.1354 - val_acc: 0.4095\n",
            "Epoch 13/16\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.5757 - acc: 0.8145 - val_loss: 2.0836 - val_acc: 0.4315\n",
            "Epoch 14/16\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.5013 - acc: 0.8429 - val_loss: 2.2792 - val_acc: 0.4165\n",
            "Epoch 15/16\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.4327 - acc: 0.8624 - val_loss: 2.4130 - val_acc: 0.4035\n",
            "Epoch 16/16\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.3653 - acc: 0.8869 - val_loss: 2.3283 - val_acc: 0.4355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rt0R_1giGEuK",
        "outputId": "9c93c265-075a-487d-d6b6-e5829774c952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "model_conv3.evaluate(x_test, y_test)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 4s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3283257150650023, 0.4355]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "MzM_maLIhhdr",
        "colab_type": "code",
        "outputId": "279f6b5e-c4de-435e-e687-0e6cfaf6847d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "model_conv3.evaluate(x_train, y_train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7999/7999 [==============================] - 16s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.22807032822750406, 0.9424928116089017]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kwaGx5Y8aa6v"
      },
      "cell_type": "markdown",
      "source": [
        "#### 4. Simple Pooling Model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6Q-j-IriadPv",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#ref: https://github.com/keras-team/keras/blob/master/examples/imdb_fasttext.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uoX7381Uad0f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model4 = Sequential()\n",
        "model4.add(Embedding(input_dim=max_features,\n",
        "                    output_dim=30))\n",
        "\n",
        "# we add a GlobalAveragePooling1D, which will average the embeddings\n",
        "# of all words in the document\n",
        "model4.add(GlobalAveragePooling1D())\n",
        "model4.add(Dropout(0.5))\n",
        "\n",
        "model4.add(Dense(14, activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iHCRHm-pad3E",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt = keras.optimizers.Adam(lr=0.01) # speed up optimization\n",
        "model4.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NOpgYwlcad5s",
        "outputId": "91cfc858-ed88-4244-943f-b55a384ede54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "cell_type": "code",
      "source": [
        "history4 = model4.fit(x_train, y_train,\n",
        "            batch_size=256,\n",
        "            epochs=16,\n",
        "            validation_data=(x_test, y_test))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7999 samples, validate on 2000 samples\n",
            "Epoch 1/16\n",
            "7999/7999 [==============================] - 1s 103us/step - loss: 2.6238 - acc: 0.1069 - val_loss: 2.6021 - val_acc: 0.1670\n",
            "Epoch 2/16\n",
            "7999/7999 [==============================] - 0s 40us/step - loss: 2.5610 - acc: 0.1939 - val_loss: 2.5138 - val_acc: 0.2105\n",
            "Epoch 3/16\n",
            "7999/7999 [==============================] - 0s 40us/step - loss: 2.4445 - acc: 0.2475 - val_loss: 2.3846 - val_acc: 0.3295\n",
            "Epoch 4/16\n",
            "7999/7999 [==============================] - 0s 41us/step - loss: 2.2985 - acc: 0.3240 - val_loss: 2.2463 - val_acc: 0.3530\n",
            "Epoch 5/16\n",
            "7999/7999 [==============================] - 0s 39us/step - loss: 2.1385 - acc: 0.3793 - val_loss: 2.1139 - val_acc: 0.4160\n",
            "Epoch 6/16\n",
            "7999/7999 [==============================] - 0s 42us/step - loss: 1.9879 - acc: 0.4368 - val_loss: 1.9943 - val_acc: 0.4325\n",
            "Epoch 7/16\n",
            "7999/7999 [==============================] - 0s 40us/step - loss: 1.8418 - acc: 0.4917 - val_loss: 1.8902 - val_acc: 0.4470\n",
            "Epoch 8/16\n",
            "7999/7999 [==============================] - 0s 39us/step - loss: 1.7073 - acc: 0.5401 - val_loss: 1.7917 - val_acc: 0.5030\n",
            "Epoch 9/16\n",
            "7999/7999 [==============================] - 0s 39us/step - loss: 1.5805 - acc: 0.5898 - val_loss: 1.7006 - val_acc: 0.5250\n",
            "Epoch 10/16\n",
            "7999/7999 [==============================] - 0s 39us/step - loss: 1.4600 - acc: 0.6343 - val_loss: 1.6222 - val_acc: 0.5435\n",
            "Epoch 11/16\n",
            "7999/7999 [==============================] - 0s 41us/step - loss: 1.3541 - acc: 0.6607 - val_loss: 1.5519 - val_acc: 0.5740\n",
            "Epoch 12/16\n",
            "7999/7999 [==============================] - 0s 40us/step - loss: 1.2632 - acc: 0.6931 - val_loss: 1.4938 - val_acc: 0.5930\n",
            "Epoch 13/16\n",
            "7999/7999 [==============================] - 0s 39us/step - loss: 1.1646 - acc: 0.7238 - val_loss: 1.4379 - val_acc: 0.5940\n",
            "Epoch 14/16\n",
            "7999/7999 [==============================] - 0s 41us/step - loss: 1.0870 - acc: 0.7501 - val_loss: 1.3915 - val_acc: 0.6030\n",
            "Epoch 15/16\n",
            "7999/7999 [==============================] - 0s 39us/step - loss: 1.0096 - acc: 0.7756 - val_loss: 1.3481 - val_acc: 0.6155\n",
            "Epoch 16/16\n",
            "7999/7999 [==============================] - 0s 40us/step - loss: 0.9489 - acc: 0.7885 - val_loss: 1.3196 - val_acc: 0.6300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pHXxs7SMcevP",
        "outputId": "cb61178f-3cd9-4261-e5c1-d58d17e84e07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('accuracy', model4.evaluate(x_test, y_test)[1])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 0s 61us/step\n",
            "accuracy 0.63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MfkuRbGbh9jD",
        "colab_type": "code",
        "outputId": "ee6d5db1-01f9-4c04-caab-7ed57b44f0c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('accuracy', model4.evaluate(x_train, y_train)[1])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7999/7999 [==============================] - 0s 56us/step\n",
            "accuracy 0.8828603575521446\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
