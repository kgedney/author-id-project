{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Pre_Processing_NNDL.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "8wGkZjxy9gXr",
        "colab_type": "code",
        "outputId": "117cf890-9241-43d8-fe9c-b6f7da2e80d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YyyBXVXa8RRC",
        "colab_type": "code",
        "outputId": "4ff02bb1-8aca-4e43-8342-77751d522ea1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')\n",
        "from nltk.tag import StanfordNERTagger\n",
        "\n",
        "import string\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0RdNWgB18RRE",
        "colab_type": "code",
        "outputId": "7e5468aa-c4f3-4c3e-8681-3684de2e825d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "from nltk.tag import StanfordNERTagger\n",
        "\n",
        "#Check that paths are set properly for local host\n",
        "jar = 'drive/My Drive/Colab Notebooks/stanford-ner.jar'\n",
        "model = 'drive/My Drive/Colab Notebooks/english.all.3class.distsim.crf.ser.gz'\n",
        "\n",
        "ner_tagger = StanfordNERTagger(model, jar, encoding='utf8')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
            "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
            "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
            "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ah7mDNitli-j",
        "colab_type": "code",
        "outputId": "8a22e03a-ef5e-4bff-cd43-5200f24b9e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get update"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hit:1 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [83.2 kB]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Release\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [266 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [575 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [122 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [738 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [3,433 B]\n",
            "Fetched 1,951 kB in 3s (603 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "khB8svR9GSRP",
        "colab_type": "code",
        "outputId": "45c6dd37-96f5-4061-ee85-8ba53b80fd65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import os    \n",
        "def install_java():\n",
        "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      \n",
        "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     \n",
        "  !java -version      \n",
        "install_java()\n",
        "\n",
        "#Taken from: https://stackoverflow.com/questions/51287258/how-can-i-use-java-in-google-colab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_191\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_191-8u191-b12-0ubuntu0.18.04.1-b12)\n",
            "OpenJDK 64-Bit Server VM (build 25.191-b12, mixed mode)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ylcoNrph8RRG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Function \"load\" takes a .csv file as the parameter. It reads the .csv file and returns \n",
        "the file as a list of lists.\n",
        "'''\n",
        "\n",
        "def load(text):\n",
        "    lines = []\n",
        "    with open(text) as f:\n",
        "        reader = csv.reader(f)\n",
        "        for row in reader:\n",
        "            lines.append(row)\n",
        "    return lines"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LzSD1NUh8RRI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Load csv\n",
        "txt_files = load('drive/My Drive/Colab Notebooks/filtered_data_sub.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gyTq_YfV8RRK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# [x][0] gives author\n",
        "# [x][1] gives body"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oQVibFLk8RRM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create list of unique authors\n",
        "author_names = []\n",
        "for i in range(len(txt_files)):\n",
        "    temp_string = txt_files[i][0]\n",
        "    author_names.append(temp_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OUceBrLY8RRO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load comments\n",
        "work_loaded = []\n",
        "for i in range(len(txt_files)):\n",
        "    temp_string = txt_files[i][1]\n",
        "    work_loaded.append(temp_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c3ajjU-Smj5X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#replace urls in comments\n",
        "work =list(map(lambda x: re.sub(r\"http\\S+\", \"<url>\",x ), work_loaded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MrIuQd4h8RRQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Replace digits with '0'\n",
        "digits = []\n",
        "for word in work:\n",
        "    temp_string = \"\".join(word)\n",
        "    replaced_string = re.sub('\\d', '0', temp_string)\n",
        "    digits.append(replaced_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HD3TMS6r8RRT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Tokenize text\n",
        "work_tokenized = []\n",
        "for word in digits:\n",
        "    work_tokenized.append(word_tokenize(word))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bA9WqZW58RRV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Replace tokens tagged as PERSON, ORGANIZATION, or LOCATION with '#'\n",
        "final_tokens = []\n",
        "for i in range((len(work_tokenized))):\n",
        "            tag_tokens = ner_tagger.tag(work_tokenized[i])\n",
        "            tag_df = pd.DataFrame(tag_tokens, columns=['token', 'label'])\n",
        "            tag_df.loc[tag_df.label == \"PERSON\", 'token'] = \"#\"\n",
        "            tag_df.loc[tag_df.label == \"ORGANIZATION\", 'token'] = \"#\"\n",
        "            tag_df.loc[tag_df.label == \"LOCATION\", 'token'] = \"#\"\n",
        "            new_tokens = list(tag_df['token'])\n",
        "            final_tokens.append(new_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aH0fR9zR8RRX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create dictionary for authors with their corresponding tokens\n",
        "works = {'author': author_names,\n",
        "         'work': final_tokens}\n",
        "author_works_df = pd.DataFrame.from_dict(works)\n",
        "author_works_dict = {x: y[\"work\"].tolist() for x,y in author_works_df.groupby(\"author\")}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z3leRTa28RRZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Write author/tokens dictionary to .txt file\n",
        "with open('authors_tokens_dict.txt', 'w') as file:\n",
        "     file.write(json.dumps(author_works_dict))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-v70t-U98RRb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Write author/tokens dictionary to .csv file\n",
        "with open('authors_tokens_dict.csv', 'w') as csv_file:\n",
        "    writer = csv.writer(csv_file)\n",
        "    for key, value in author_works_dict.items():\n",
        "        writer.writerow([key, value])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dorVpUETVr5_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "author_works_df.to_csv('author_tokens_df.csv', encoding='utf-8', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SDPVDq-i8RRf",
        "colab_type": "code",
        "outputId": "901af1a9-e709-4587-e10a-cfe4b9270074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "csv.field_size_limit(100000000)\n",
        "with open('authors_tokens_dict.csv', 'r') as csv_file:\n",
        "    reader = csv.reader(csv_file)\n",
        "    mydict = dict(reader)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ncsv.field_size_limit(100000000)\\nwith open('authors_tokens.csv', 'r') as csv_file:\\n    reader = csv.reader(csv_file)\\n    mydict = dict(reader)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "5V2wueZO8RRl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E7dUVily8RRm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}